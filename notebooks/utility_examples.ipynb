{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions Examples\n",
    "\n",
    "**Author:** Luis Paulo Vinatea Barberena  \n",
    "**Date:** May 21, 2025\n",
    "\n",
    "This notebook demonstrates how to use the utility functions in `src/utils/` to streamline your data analysis workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import utility functions\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils.data_processing import clean_missing_values, detect_outliers, encode_categorical\n",
    "from src.utils.visualization import plot_correlation_matrix, plot_distribution, plot_missing_values\n",
    "from src.utils.notebook_utils import create_notebook_template\n",
    "\n",
    "# For visualization\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Sample Data\n",
    "\n",
    "Let's create some sample data to demonstrate the utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'numeric_1': np.random.normal(0, 1, n_samples),\n",
    "    'numeric_2': np.random.normal(5, 2, n_samples),\n",
    "    'numeric_3': np.random.exponential(2, n_samples),\n",
    "    'category_1': np.random.choice(['A', 'B', 'C', 'D'], n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'category_2': np.random.choice(['X', 'Y', 'Z'], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "    'date': pd.date_range(start='2024-01-01', periods=n_samples)\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add some correlations\n",
    "df['numeric_4'] = df['numeric_1'] * 2 + df['numeric_2'] + np.random.normal(0, 0.5, n_samples)\n",
    "\n",
    "# Add some missing values\n",
    "for col in df.columns[:4]:  # Skip date column\n",
    "    mask = np.random.random(n_samples) < 0.1  # 10% missing values\n",
    "    df.loc[mask, col] = np.nan\n",
    "    \n",
    "# Add some outliers\n",
    "for col in ['numeric_1', 'numeric_2', 'numeric_3']:\n",
    "    outlier_idx = np.random.choice(n_samples, 5, replace=False)\n",
    "    df.loc[outlier_idx, col] = np.random.uniform(10, 20, 5)\n",
    "    \n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing Utilities\n",
    "\n",
    "Let's demonstrate the data processing utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Clean missing values using different strategies\n",
    "print(\"\\nCleaning with different strategies:\")\n",
    "strategies = ['drop', 'mean', 'median', 'fill']\n",
    "for strategy in strategies:\n",
    "    kwargs = {'fill_value': 0} if strategy == 'fill' else {}\n",
    "    df_cleaned = clean_missing_values(df, strategy=strategy, **kwargs)\n",
    "    print(f\"\\nStrategy: {strategy}\")\n",
    "    print(f\"Original shape: {df.shape}, Cleaned shape: {df_cleaned.shape}\")\n",
    "    print(f\"Missing values after cleaning: {df_cleaned.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using different methods\n",
    "numeric_cols = ['numeric_1', 'numeric_2', 'numeric_3', 'numeric_4']\n",
    "\n",
    "# Using IQR method\n",
    "outliers_iqr = detect_outliers(df, method='iqr', columns=numeric_cols)\n",
    "print(\"Outliers detected using IQR method:\")\n",
    "for col in numeric_cols:\n",
    "    n_outliers = outliers_iqr[col].sum()\n",
    "    print(f\"{col}: {n_outliers} outliers ({n_outliers/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Using Z-score method\n",
    "outliers_zscore = detect_outliers(df, method='zscore', columns=numeric_cols, threshold=3.0)\n",
    "print(\"\\nOutliers detected using Z-score method:\")\n",
    "for col in numeric_cols:\n",
    "    n_outliers = outliers_zscore[col].sum()\n",
    "    print(f\"{col}: {n_outliers} outliers ({n_outliers/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Visualize one column with outliers\n",
    "col = 'numeric_1'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(df)), df[col], alpha=0.5, label='Data points')\n",
    "plt.scatter(df.index[outliers_iqr[col]], df.loc[outliers_iqr[col], col], \n",
    "            color='red', label='Outliers (IQR)')\n",
    "plt.title(f'Outlier Detection for {col} using IQR Method')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel(col)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using different methods\n",
    "categorical_cols = ['category_1', 'category_2']\n",
    "\n",
    "# One-hot encoding\n",
    "df_onehot = encode_categorical(df, columns=categorical_cols, method='onehot')\n",
    "print(\"One-hot encoded:\")\n",
    "print(df_onehot.head())\n",
    "print(f\"Original columns: {df.columns.tolist()}\")\n",
    "print(f\"Encoded columns: {df_onehot.columns.tolist()}\")\n",
    "\n",
    "# Label encoding\n",
    "df_label = encode_categorical(df, columns=categorical_cols, method='label')\n",
    "print(\"\\nLabel encoded:\")\n",
    "print(df_label.head())\n",
    "\n",
    "# Compare original and encoded dataframes\n",
    "for col in categorical_cols:\n",
    "    unique_vals = df[col].unique()\n",
    "    encoded_vals = df_label[col].unique()\n",
    "    print(f\"\\n{col} mapping:\")\n",
    "    for orig, enc in zip(sorted(unique_vals), sorted(encoded_vals)):\n",
    "        print(f\"  {orig} -> {enc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization Utilities\n",
    "\n",
    "Let's demonstrate the visualization utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data first (use median strategy to preserve relationships)\n",
    "df_clean = clean_missing_values(df, strategy='median')\n",
    "\n",
    "# Plot correlation matrix\n",
    "plot_correlation_matrix(df_clean[numeric_cols], figsize=(10, 8), \n",
    "                       method='pearson', cmap='coolwarm', \n",
    "                       mask_upper=True, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of a numeric column\n",
    "for col in numeric_cols[:2]:  # Plot first two numeric columns\n",
    "    plot_distribution(df_clean, column=col, bins=30, kde=True, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Missing Value Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot missing values in the original dataframe\n",
    "plot_missing_values(df, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Notebook Generation Utility\n",
    "\n",
    "Let's demonstrate how to create a new notebook template using the utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new notebook template\n",
    "output_path = \"../notebooks/new_analysis_demo.ipynb\"\n",
    "create_notebook_template(\n",
    "    output_path=output_path, \n",
    "    title=\"Customer Segmentation Analysis\", \n",
    "    author=\"Luis Paulo Vinatea Barberena\"\n",
    ")\n",
    "\n",
    "print(f\"A new notebook template has been created at {output_path}\")\n",
    "print(\"You can use this utility to quickly create standardized notebook templates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the utility functions from `src/utils/` to streamline your data analysis workflows:\n",
    "\n",
    "1. **Data Processing Utilities**:\n",
    "   - Handling missing values with different strategies\n",
    "   - Detecting and visualizing outliers\n",
    "   - Encoding categorical variables\n",
    "\n",
    "2. **Visualization Utilities**:\n",
    "   - Creating correlation matrices\n",
    "   - Plotting distributions\n",
    "   - Visualizing missing values\n",
    "\n",
    "3. **Notebook Generation Utility**:\n",
    "   - Creating standardized notebook templates\n",
    "\n",
    "These utilities help maintain consistency across analyses and save time by eliminating the need to rewrite common code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
